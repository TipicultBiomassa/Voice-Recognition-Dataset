{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "diagnostic-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "complicated-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data directories\n",
    "data_dir = \"./\"\n",
    "#os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "academic-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wav paths\n",
    "def get_wav_paths(speaker):\n",
    "    speaker_path = data_dir + speaker\n",
    "    all_paths = [item for item in os.listdir(speaker_path)]\n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "wanted-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "Putin_paths = get_wav_paths(\"Putin\")\n",
    "Elcin_paths = get_wav_paths(\"Elcin\")\n",
    "#print(Elcin_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "lightweight-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "def load_wav(wav_path, speaker):\n",
    "    with tf.compat.v1.Session(graph=tf.compat.v1.Graph()) as sess:\n",
    "        wav_path = data_dir + speaker + \"/\" + wav_path\n",
    "        wav_filename_placeholder = tf.compat.v1.placeholder(tf.compat.v1.string, [])\n",
    "        wav_loader = tf.io.read_file(wav_filename_placeholder)\n",
    "        wav_decoder = tf.audio.decode_wav(wav_loader, desired_channels=1)\n",
    "        #wav_data = sess.run(\n",
    "        #    wav_decoder, feed_dict={\n",
    "        #        wav_filename_placeholder: wav_path\n",
    "        #    }).audio.flatten().reshape((1, 16000))\n",
    "        wav_data = sess.run(\n",
    "            wav_decoder, feed_dict={\n",
    "                wav_filename_placeholder: wav_path\n",
    "            }).audio.flatten().reshape((1, 16000))\n",
    "        sess.close()\n",
    "    return wav_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "intellectual-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data\n",
    "def generate_training_data(speaker_paths, speaker, label):\n",
    "    wavs, labels = [], []\n",
    "    for i in tqdm(speaker_paths):\n",
    "        wav = load_wav(i, speaker)\n",
    "        wavs.append(wav)\n",
    "        labels.append(label)\n",
    "    return wavs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "exciting-islam",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1652/1652 [00:06<00:00, 262.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1386/1386 [00:05<00:00, 261.59it/s]\n"
     ]
    }
   ],
   "source": [
    "Putin_wavs, Putin_labels = generate_training_data(Putin_paths, \"Putin\", 0) \n",
    "Elcin_wavs, Elcin_labels = generate_training_data(Elcin_paths, \"Elcin\", 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "assured-violation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Rate: 16000\n",
      "Shape: (1, 16000)\n",
      "Dtype: torch.float32\n",
      " - Max:      0.616\n",
      " - Min:     -0.601\n",
      " - Mean:     0.000\n",
      " - Std Dev:  0.108\n",
      "\n",
      "tensor([[-3.0518e-05, -3.9673e-04, -3.3569e-04,  ...,  9.7717e-02,\n",
      "          8.1818e-02,  6.1951e-02]])\n",
      "\n",
      "----------\n",
      "Source: ./Elcin/0.wav\n",
      "----------\n",
      " - sample_rate: 16000\n",
      " - num_channels: 1\n",
      " - num_frames: 16000\n",
      " - bits_per_sample: 16\n",
      " - encoding: PCM_S\n",
      "\n",
      "----------\n",
      "Source: ./Putin/0.wav\n",
      "----------\n",
      " - sample_rate: 16000\n",
      " - num_channels: 1\n",
      " - num_frames: 16000\n",
      " - bits_per_sample: 16\n",
      " - encoding: PCM_S\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Не нужно для нейросети, просто информация о данных\n",
    "def print_stats(waveform, sample_rate=None, src=None):\n",
    "  if src:\n",
    "    print(\"-\" * 10)\n",
    "    print(\"Source:\", src)\n",
    "    print(\"-\" * 10)\n",
    "  if sample_rate:\n",
    "    print(\"Sample Rate:\", sample_rate)\n",
    "  print(\"Shape:\", tuple(waveform.shape))\n",
    "  print(\"Dtype:\", waveform.dtype)\n",
    "  print(f\" - Max:     {waveform.max().item():6.3f}\")\n",
    "  print(f\" - Min:     {waveform.min().item():6.3f}\")\n",
    "  print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n",
    "  print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n",
    "  print()\n",
    "  print(waveform)\n",
    "  print()\n",
    "def print_metadata(metadata, src=None):\n",
    "  if src:\n",
    "    print(\"-\" * 10)\n",
    "    print(\"Source:\", src)\n",
    "    print(\"-\" * 10)\n",
    "  print(\" - sample_rate:\", metadata.sample_rate)\n",
    "  print(\" - num_channels:\", metadata.num_channels)\n",
    "  print(\" - num_frames:\", metadata.num_frames)\n",
    "  print(\" - bits_per_sample:\", metadata.bits_per_sample)\n",
    "  print(\" - encoding:\", metadata.encoding)\n",
    "  print()\n",
    "\n",
    "waveform, sample_rate = torchaudio.load('./Elcin/0.wav')\n",
    "print_stats(waveform, sample_rate=sample_rate)\n",
    "\n",
    "metadata = torchaudio.info('./Elcin/0.wav')\n",
    "print_metadata(metadata, src='./Elcin/0.wav')\n",
    "\n",
    "metadata = torchaudio.info('./Putin/0.wav')\n",
    "print_metadata(metadata, src='./Putin/0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "reduced-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wavs = Putin_wavs + Elcin_wavs\n",
    "all_labels = Putin_labels + Elcin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "molecular-letter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3038, 1, 16000) (3038,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_wavs = np.array(all_wavs)\n",
    "final_labels = np.array(all_labels)\n",
    "\n",
    "print(final_wavs.shape, final_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "satisfied-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wavs, test_wavs, train_labels, test_labels = train_test_split(final_wavs, final_labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "least-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = np.array(train_wavs), np.array(train_labels)\n",
    "test_x, test_y = np.array(test_wavs), np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "practical-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = tf.keras.utils.to_categorical(train_y)\n",
    "test_y = tf.keras.utils.to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "instant-construction",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParameterError",
     "evalue": "Invalid shape for monophonic audio: ndim=2, shape=(1, 16000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParameterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-09ce0389e853>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmfcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mmfcc_delta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmfcc_double_delta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\librosa\\feature\\spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[1;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m         \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m     \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdct_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_mfcc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\librosa\\feature\\spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[1;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[0;32m   1994\u001b[0m     \"\"\"\n\u001b[0;32m   1995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1996\u001b[1;33m     S, n_fft = _spectrogram(\n\u001b[0m\u001b[0;32m   1997\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1998\u001b[0m         \u001b[0mS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\librosa\\core\\spectrum.py\u001b[0m in \u001b[0;36m_spectrogram\u001b[1;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[0;32m   2510\u001b[0m         S = (\n\u001b[0;32m   2511\u001b[0m             np.abs(\n\u001b[1;32m-> 2512\u001b[1;33m                 stft(\n\u001b[0m\u001b[0;32m   2513\u001b[0m                     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2514\u001b[0m                     \u001b[0mn_fft\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\librosa\\core\\spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[1;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;31m# Check audio is valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_audio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;31m# Pad the time series so that frames are centered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\librosa\\util\\utils.py\u001b[0m in \u001b[0;36mvalid_audio\u001b[1;34m(y, mono)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmono\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         raise ParameterError(\n\u001b[0m\u001b[0;32m    294\u001b[0m             \u001b[1;34m\"Invalid shape for monophonic audio: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;34m\"ndim={:d}, shape={}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mParameterError\u001b[0m: Invalid shape for monophonic audio: ndim=2, shape=(1, 16000)"
     ]
    }
   ],
   "source": [
    "train_x_new = []\n",
    "test_x_new = []\n",
    "INPUT_SHAPE = (126,40)\n",
    "\n",
    "train_x_new = np.zeros((train_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n",
    "\n",
    "count = 0\n",
    "for sample in train_x:\n",
    "    mfcc = librosa.feature.mfcc(y=sample, sr=16000, hop_length=128, n_fft=256, n_mfcc=20)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)[:10, :]\n",
    "    mfcc_double_delta = librosa.feature.delta(mfcc, order=2)[:10, :]\n",
    "    train_x_new[count, :, :20] = mfcc.T\n",
    "    train_x_new[count, :, 20:30] = mfcc_delta.T\n",
    "    train_x_new[count, :, 30:] = mfcc_double_delta.T\n",
    "    count += 1\n",
    "    if count%500 == 0:\n",
    "        print('Train', count)\n",
    "        \n",
    "test_x_new = np.zeros((test_x.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1]), dtype=np.float64)\n",
    "\n",
    "count = 0\n",
    "for sample in test_x:\n",
    "    mfcc = librosa.feature.mfcc(y=sample, sr=16000, hop_length=128, n_fft=256, n_mfcc=20)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)[:10, :]\n",
    "    mfcc_double_delta = librosa.feature.delta(mfcc, order=2)[:10, :]\n",
    "    test_x_new[count, :, :20] = mfcc.T\n",
    "    test_x_new[count, :, 20:30] = mfcc_delta.T\n",
    "    test_x_new[count, :, 30:] = mfcc_double_delta.T\n",
    "    count += 1\n",
    "    if count%500 == 0:\n",
    "        print('Test', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-panel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-garbage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-monitoring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-provider",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
